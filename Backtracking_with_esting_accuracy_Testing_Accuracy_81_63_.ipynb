{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGX6g/DhU+ShcXd4jBgC6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhuvan340/My-Machine-Learning-Files/blob/main/Backtracking_with_esting_accuracy_Testing_Accuracy_81_63_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('1962_2021.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separate input features and the target variable\n",
        "X = data.drop(columns=['Candidates_Represented'])  # Input features\n",
        "y = data['Candidates_Represented']  # Target variable\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = [col for col in X.columns if col not in numerical_cols]\n",
        "\n",
        "# Preprocess numerical columns by scaling\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "# Preprocess categorical columns using one-hot encoding\n",
        "X_categorical = X[categorical_cols]\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "X_categorical_encoded = encoder.fit_transform(X_categorical)\n",
        "\n",
        "# Concatenate processed numerical and categorical columns\n",
        "X_processed = np.concatenate((X[numerical_cols], X_categorical_encoded), axis=1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "\n",
        "# Implement the Neural Network class and the rest of the code (as shown in the previous examples)\n",
        "# ...\n",
        "\n",
        "# Training the neural network and making predictions remains the same\n",
        "# ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np1t-NGRXjXh",
        "outputId": "5110c1b8-81b1-4074-97a4-3a99cb33e102"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Implementing a simple neural network using NumPy for backpropagation\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        np.random.seed(1)\n",
        "        self.weights = np.random.rand(X_train.shape[1], 1)\n",
        "        self.bias = np.random.rand(1)\n",
        "        self.lr = 0.01  # Learning rate\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, X, y, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            # Forward propagation\n",
        "            weighted_sum = np.dot(X, self.weights) + self.bias\n",
        "            activated_output = self.sigmoid(weighted_sum)\n",
        "\n",
        "            # Calculating error\n",
        "            error = y - activated_output\n",
        "\n",
        "            # Backpropagation\n",
        "            adjustments = error * self.sigmoid_derivative(activated_output)\n",
        "            self.weights += np.dot(X.T, adjustments) * self.lr\n",
        "            self.bias += np.sum(adjustments) * self.lr\n",
        "\n",
        "    def predict(self, X):\n",
        "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
        "        return self.sigmoid(weighted_sum)\n",
        "\n",
        "# Training the neural network\n",
        "nn = NeuralNetwork()\n",
        "epochs = 1000  # Define number of epochs\n",
        "nn.train(X_train, y_train, epochs)\n",
        "\n",
        "# Making predictions on the test set\n",
        "predictions_test = nn.predict(X_test)\n",
        "\n",
        "# Calculating accuracy for testing\n",
        "accuracy_test = np.mean((predictions_test.round() == y_test.values.reshape(-1, 1)))\n",
        "print(f\"Testing Accuracy: {accuracy_test * 100:.2f}%\")\n",
        "\n",
        "# Make predictions for new input\n",
        "# Assuming 'new_input' is a new set of features for prediction\n",
        "# Assuming 'new_input' is a new set of features for prediction\n",
        "new_input = np.array([\n",
        "    [3, 'StateA', 'PartyX', 'TypeY', 123, 'AbbrevX', 'LastAbbrevX', 'Abbrs', 2020, 2022, 8, 5, 200, 150, 50, 40, 2, 2, 1, 1, 0],\n",
        "    [5, 'StateB', 'PartyY', 'TypeZ', 456, 'AbbrevY', 'LastAbbrevY', 'Abbrt', 2018, 2023, 6, 4, 180, 120, 40, 30, 2, 1, 1, 1, 0]\n",
        "])\n",
        "\n",
        "full_data = pd.concat([data, pd.DataFrame(new_input, columns=data.columns)], ignore_index=True)\n",
        "\n",
        "# Fit the encoder on the concatenated dataset to capture all categories\n",
        "encoder.fit(full_data[categorical_cols])\n",
        "\n",
        "# Separate the numerical and categorical columns for the new input\n",
        "numerical_cols_mask = np.isin(full_data.columns, numerical_cols)\n",
        "categorical_cols_mask = ~numerical_cols_mask\n",
        "\n",
        "new_input_numerical = new_input[:, numerical_cols_mask]\n",
        "new_input_categorical = new_input[:, categorical_cols_mask]\n",
        "\n",
        "# Encode the categorical columns for the new input using the fitted encoder\n",
        "new_input_categorical_encoded = encoder.transform(new_input_categorical)\n",
        "\n",
        "# Combine the processed numerical and encoded categorical columns for the new input\n",
        "new_input_combined = np.concatenate((new_input_numerical, new_input_categorical_encoded), axis=1)\n",
        "\n",
        "# Make predictions for the new input using the trained neural network\n",
        "predicted_output = nn.predict(new_input_combined)\n",
        "print(\"Predicted Output for New Input:\", predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "cseMhl2YXuU4",
        "outputId": "7f26cb6f-a8d3-4848-d2d9-8e68f8448ff6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 81.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a122596e78c8>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Encode the categorical columns for the new input using the fitted encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mnew_input_categorical_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Combine the processed numerical and encoded categorical columns for the new input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;34m\"infrequent_if_exist\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         }\n\u001b[0;32m--> 917\u001b[0;31m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    153\u001b[0m     ):\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         X_list, n_samples, n_features = self._check_X(\n\u001b[1;32m    157\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 9 features, but OneHotEncoder is expecting 8 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejwQX4USX1jI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}